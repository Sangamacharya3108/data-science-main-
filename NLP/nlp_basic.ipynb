{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e3c467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, i am sangam\n"
     ]
    }
   ],
   "source": [
    "## casefold\n",
    "text='Hello, I Am Sangam'.casefold()\n",
    "print(text)\n",
    "\n",
    "\n",
    "# if we train any modle it must be casefold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db88b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, welcome to upflairs\n"
     ]
    }
   ],
   "source": [
    "test=\"HEllo, Welcome to Upflairs\".lower()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3888010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b44694ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello my name is sangam'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imput=\"hello, m@y name is sangam#\"\n",
    "clean_input=re.sub(r'[^a-zA-Z0-9\\s]','',imput)\n",
    "clean_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bfc2858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is sangam1234578 '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1=\"my@ name is #sangam1234578 \"\n",
    "clean_input1=re.sub(r'[^a-zA-Z0-9\\s]','',input1)\n",
    "clean_input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd090c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is sangam1234578 '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2=\"my@ name is #sangam1234578 \"\n",
    "clean_input2=re.sub(r'[^a-zA-Z0-9\\s]',\"\",input2)\n",
    "clean_input2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4e862",
   "metadata": {},
   "source": [
    "Handling Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78cb0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm = i am\n",
    "# i'm going = i am going\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "602e6c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am going\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "text=\"i'm going\"\n",
    "expanded_text=contractions.fix(text)\n",
    "print(expanded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0ac5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e002043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\MSI\n",
      "[nltk_data]     INDIA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7a34503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\MSI\n",
      "[nltk_data]     INDIA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97931812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', 'm', '@', 'y', 'name', 'is', 'sangam', '#', '#']\n",
      "hello m y name is sangam\n"
     ]
    }
   ],
   "source": [
    "inputt=\"hello, m@y name is sangam##\"\n",
    "tokens=nltk.word_tokenize(inputt)\n",
    "print(tokens)\n",
    "\n",
    "clean_text=[token for token in tokens if token.isalnum()]\n",
    "cleaned_text=' '.join(clean_text)\n",
    "print(cleaned_text)\n",
    "\n",
    "\n",
    "# handles url, emoji and all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7957a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc=\"hello, m@y name is sangam##\"\n",
    "# clean_abc=[token for token in abc if abc.isalnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38008389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sangam is '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence= \"sangam is https://pypi.org/project/nltk/\"\n",
    "import re\n",
    "re.sub(r'https?://\\S+|www\\.\\S+','', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34faa48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_word_dict={\n",
    "    \"u\":\"you\",\n",
    "    \"ur\":\"your\",\n",
    "    \"r\":\"are\",\n",
    "    \"b4\":\"before\",\n",
    "    \"4u\":\"for you\",\n",
    "    \"gr8\":\"great\",\n",
    "    \"l8r\":\"later\",\n",
    "    \"cya\":\"see you\",\n",
    "    \"pls\":\"please\",\n",
    "    \"thx\":\"thanks\",\n",
    "    \"btw\":\"by the way\",\n",
    "    \"imo\":\"in my opinion\",\n",
    "    \"idk\":\"I don't know\",\n",
    "    \"imho\":\"in my humble opinion\",\n",
    "    \"tbh\":\"to be honest\",\n",
    "    \"fyi\":\"for your information\",\n",
    "    \"smh\":\"shaking my head\",\n",
    "    \"lol\":\"laugh out loud\",\n",
    "    \"omg\":\"oh my god\",\n",
    "    \"brb\":\"be right back\",\n",
    "    \"ttyl\":\"talk to you later\",\n",
    "    \"btw\":\"by the way\",\n",
    "    \"fomo\":\"fear of missing out\",\n",
    "    \"lmao\":\"laughing my ass off\",\n",
    "    \"wbu\":\"what about you\",\n",
    "    \"xoxo\":\"hugs and kisses\",\n",
    "    \"jk\":\"just kidding\",\n",
    "    \"gm\":\"good morning\",\n",
    "    \"gn\":\"good night\",\n",
    "    \"fomo\":\"fear of missing out\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"smh\":\"shaking my head\",\n",
    "    \"afk\":\"away from keyboard\",\n",
    "    \"ppl\":\"people\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"ttys\": \"talk to you soon\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"dunno\": \"don’t know\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"l8r\": \"later\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b276f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_text=\"omg idk what u r talking about lol\"\n",
    "def normalize_text (chat_text):\n",
    "    words=chat_text.split()\n",
    "    normalize_words=[chat_word_dict.get(word.lower(), word)for word in words]          #when we assign key to get functions then it gives its value, if not then it returns the word itself\n",
    "    return \" \".join(normalize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7e5529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_text = normalize_text(chat_text = \"omg idk what u r talking about lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9a657d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"oh my god I don't know what you are talking about laugh out loud\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a3006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am a student\n"
     ]
    }
   ],
   "source": [
    "#pip install TextBlob\n",
    "\n",
    "from textblob import TextBlob\n",
    "text = \"i am a stadant\"\n",
    "spelling_correct = TextBlob(text).correct()\n",
    "print(spelling_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14634409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak now\n",
      "Sorry could not recognize your voice\n"
     ]
    }
   ],
   "source": [
    "#pip install SpeechRecognition        \n",
    "#pip install pyaudio\n",
    "\n",
    "import speech_recognition as sr \n",
    "recognizer=sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"speak now\")\n",
    "    audio = recognizer.listen(source)\n",
    "try:\n",
    "    text= recognizer.recognize_google(audio)\n",
    "    print(\"you said:\",text)\n",
    "except:\n",
    "    print(\"Sorry could not recognize your voice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa90c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text to speech (tts)\n",
    "#pip install gtts\n",
    "\n",
    "from gtts import gTTS\n",
    "import os\n",
    "text = \"Hello welcome to Upflairs\"\n",
    "tts=gTTS(text = text, lang=\"en\")\n",
    "tts.save(\"welcome.mp3\")\n",
    "os.system(\"welcome.mp3\")\n",
    "\n",
    "# text preprocessing done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b82a6",
   "metadata": {},
   "source": [
    "text vectorization: word convert into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec34ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use bow(bag of words) for text vectorization\n",
    "# it fails when we give any words out of vocabulary or big sentences like (this is a good movie)\n",
    "\n",
    "\n",
    "# types of Ngrams: unigram, bigram, trigram, mgram\n",
    "\n",
    "# TF/IDF term frequency and inverse document freq.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14922837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
